{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"50_startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.2</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.7</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.2       136897.80        471784.10    New York  192261.83\n",
       "1   162597.7       151377.59        443898.53  California  191792.06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          False\n",
       "Administration     False\n",
       "Marketing Spend    False\n",
       "State              False\n",
       "Profit             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dataset['State'] = le.fit_transform(dataset['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>2</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>0</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>1</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>2</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>1</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  State     Profit\n",
       "0  165349.20       136897.80        471784.10      2  192261.83\n",
       "1  162597.70       151377.59        443898.53      0  191792.06\n",
       "2  153441.51       101145.55        407934.54      1  191050.39\n",
       "3  144372.41       118671.85        383199.62      2  182901.99\n",
       "4  142107.34        91391.77        366168.42      1  166187.94"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "S:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one = OneHotEncoder(categorical_features = [3])\n",
    "x = one.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one=OneHotEncoder()\n",
    "z=one.fit_transform(x[:,3:4]).toarray()\n",
    "\n",
    "x=np.delete(x,3,axis=1)\n",
    "x=np.concatenate((z,x),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 6,init = 'random_uniform',activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=3, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 3,init = 'random_uniform',activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor.add(Dense(units = 8,init = 'random_uniform',activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor.add(Dense(units = 9,init = 'random_uniform',activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 1,init = 'random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From S:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "regressor.compile (optimizer = 'adam',loss = 'mse',metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From S:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/170\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13611063552.0000 - mse: 13611063296.0000\n",
      "Epoch 2/170\n",
      "40/40 [==============================] - 0s 399us/step - loss: 13607444736.0000 - mse: 13607445504.0000\n",
      "Epoch 3/170\n",
      "40/40 [==============================] - 0s 200us/step - loss: 13602276096.0000 - mse: 13602276352.0000\n",
      "Epoch 4/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 13595920896.0000 - mse: 13595920384.0000\n",
      "Epoch 5/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 13587859200.0000 - mse: 13587859456.0000\n",
      "Epoch 6/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 13576840448.0000 - mse: 13576840192.0000\n",
      "Epoch 7/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 13564048512.0000 - mse: 13564048384.0000\n",
      "Epoch 8/170\n",
      "40/40 [==============================] - 0s 449us/step - loss: 13547738368.0000 - mse: 13547738112.0000\n",
      "Epoch 9/170\n",
      "40/40 [==============================] - 0s 399us/step - loss: 13525914624.0000 - mse: 13525914624.0000\n",
      "Epoch 10/170\n",
      "40/40 [==============================] - 0s 399us/step - loss: 13501861120.0000 - mse: 13501860864.0000\n",
      "Epoch 11/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 13471660032.0000 - mse: 13471660032.0000\n",
      "Epoch 12/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 13431133696.0000 - mse: 13431134208.0000\n",
      "Epoch 13/170\n",
      "40/40 [==============================] - 0s 363us/step - loss: 13392881408.0000 - mse: 13392880640.0000\n",
      "Epoch 14/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 13339064576.0000 - mse: 13339064320.0000\n",
      "Epoch 15/170\n",
      "40/40 [==============================] - 0s 301us/step - loss: 13283191296.0000 - mse: 13283191808.0000\n",
      "Epoch 16/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 13210941952.0000 - mse: 13210942464.0000\n",
      "Epoch 17/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 13136208640.0000 - mse: 13136209920.0000\n",
      "Epoch 18/170\n",
      "40/40 [==============================] - 0s 424us/step - loss: 13043619328.0000 - mse: 13043619840.0000\n",
      "Epoch 19/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 12941911296.0000 - mse: 12941911040.0000\n",
      "Epoch 20/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 12821390848.0000 - mse: 12821391360.0000\n",
      "Epoch 21/170\n",
      "40/40 [==============================] - 0s 214us/step - loss: 12695554304.0000 - mse: 12695554048.0000\n",
      "Epoch 22/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 12551638528.0000 - mse: 12551638016.0000\n",
      "Epoch 23/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 12386120448.0000 - mse: 12386120704.0000\n",
      "Epoch 24/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 12215439360.0000 - mse: 12215438336.0000\n",
      "Epoch 25/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 12008405760.0000 - mse: 12008404992.0000\n",
      "Epoch 26/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 11805761664.0000 - mse: 11805761536.0000\n",
      "Epoch 27/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 11596071040.0000 - mse: 11596070912.0000\n",
      "Epoch 28/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 11326862336.0000 - mse: 11326862336.0000\n",
      "Epoch 29/170\n",
      "40/40 [==============================] - 0s 175us/step - loss: 11062938624.0000 - mse: 11062938624.0000\n",
      "Epoch 30/170\n",
      "40/40 [==============================] - ETA: 0s - loss: 11240098816.0000 - mse: 11240098816.000 - 0s 199us/step - loss: 10787060992.0000 - mse: 10787059712.0000\n",
      "Epoch 31/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 10474016512.0000 - mse: 10474015744.0000\n",
      "Epoch 32/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 10162692864.0000 - mse: 10162693120.0000\n",
      "Epoch 33/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 9811362432.0000 - mse: 9811361792.0000\n",
      "Epoch 34/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 9462729344.0000 - mse: 9462729728.0000\n",
      "Epoch 35/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 9094030208.0000 - mse: 9094030336.0000\n",
      "Epoch 36/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 8712975104.0000 - mse: 8712975360.0000\n",
      "Epoch 37/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 8299473280.0000 - mse: 8299473408.0000\n",
      "Epoch 38/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 7893930112.0000 - mse: 7893931008.0000\n",
      "Epoch 39/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 7475658880.0000 - mse: 7475659776.0000\n",
      "Epoch 40/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 7054424064.0000 - mse: 7054424576.0000\n",
      "Epoch 41/170\n",
      "40/40 [==============================] - 0s 287us/step - loss: 6634787456.0000 - mse: 6634787840.0000\n",
      "Epoch 42/170\n",
      "40/40 [==============================] - 0s 199us/step - loss: 6169298944.0000 - mse: 6169299456.0000\n",
      "Epoch 43/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 5747264128.0000 - mse: 5747264000.0000\n",
      "Epoch 44/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 5297654464.0000 - mse: 5297654272.0000\n",
      "Epoch 45/170\n",
      "40/40 [==============================] - 0s 175us/step - loss: 4895404352.0000 - mse: 4895404544.0000\n",
      "Epoch 46/170\n",
      "40/40 [==============================] - 0s 174us/step - loss: 4460896128.0000 - mse: 4460896256.0000\n",
      "Epoch 47/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 4070838080.0000 - mse: 4070838272.0000\n",
      "Epoch 48/170\n",
      "40/40 [==============================] - ETA: 0s - loss: 4233964800.0000 - mse: 4233964800.000 - 0s 249us/step - loss: 3700813056.0000 - mse: 3700813056.0000\n",
      "Epoch 49/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 3309977600.0000 - mse: 3309977600.0000\n",
      "Epoch 50/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 2953068064.0000 - mse: 2953068032.0000\n",
      "Epoch 51/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 2614630592.0000 - mse: 2614630400.0000\n",
      "Epoch 52/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 2304573312.0000 - mse: 2304573184.0000\n",
      "Epoch 53/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 2029469696.0000 - mse: 2029469696.0000\n",
      "Epoch 54/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 1762005792.0000 - mse: 1762005760.0000\n",
      "Epoch 55/170\n",
      "40/40 [==============================] - 0s 199us/step - loss: 1536179040.0000 - mse: 1536178944.0000\n",
      "Epoch 56/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 1360692672.0000 - mse: 1360692608.0000\n",
      "Epoch 57/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 1167562640.0000 - mse: 1167562624.0000\n",
      "Epoch 58/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 1019225616.0000 - mse: 1019225600.0000\n",
      "Epoch 59/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 907104272.0000 - mse: 907104384.0000\n",
      "Epoch 60/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 794841608.0000 - mse: 794841600.0000\n",
      "Epoch 61/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 712062904.0000 - mse: 712062848.0000\n",
      "Epoch 62/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 648260208.0000 - mse: 648260224.0000\n",
      "Epoch 63/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 590500608.0000 - mse: 590500608.0000\n",
      "Epoch 64/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 550763432.0000 - mse: 550763392.0000\n",
      "Epoch 65/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 527862160.0000 - mse: 527862176.0000\n",
      "Epoch 66/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 506441742.0000 - mse: 506441728.0000\n",
      "Epoch 67/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 488857680.0000 - mse: 488857696.0000\n",
      "Epoch 68/170\n",
      "40/40 [==============================] - 0s 275us/step - loss: 478284128.0000 - mse: 478284128.0000\n",
      "Epoch 69/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 469593528.0000 - mse: 469593504.0000\n",
      "Epoch 70/170\n",
      "40/40 [==============================] - 0s 374us/step - loss: 467256612.0000 - mse: 467256640.0000\n",
      "Epoch 71/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 461487024.0000 - mse: 461487008.0000\n",
      "Epoch 72/170\n",
      "40/40 [==============================] - 0s 374us/step - loss: 459791900.0000 - mse: 459791936.0000\n",
      "Epoch 73/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 456984940.0000 - mse: 456984928.0000\n",
      "Epoch 74/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 457214272.0000 - mse: 457214272.0000\n",
      "Epoch 75/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 454505512.0000 - mse: 454505472.0000\n",
      "Epoch 76/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 453516668.0000 - mse: 453516704.0000\n",
      "Epoch 77/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 451987448.0000 - mse: 451987456.0000\n",
      "Epoch 78/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 450929208.0000 - mse: 450929216.0000\n",
      "Epoch 79/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 449637368.0000 - mse: 449637376.0000\n",
      "Epoch 80/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 448770160.0000 - mse: 448770144.0000\n",
      "Epoch 81/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 447419260.0000 - mse: 447419296.0000\n",
      "Epoch 82/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 446327500.0000 - mse: 446327488.0000\n",
      "Epoch 83/170\n",
      "40/40 [==============================] - 0s 287us/step - loss: 445128798.0000 - mse: 445128800.0000\n",
      "Epoch 84/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 443913176.0000 - mse: 443913152.0000\n",
      "Epoch 85/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 442744584.0000 - mse: 442744576.0000\n",
      "Epoch 86/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 441269528.0000 - mse: 441269568.0000\n",
      "Epoch 87/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 440298544.0000 - mse: 440298560.0000\n",
      "Epoch 88/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 439089020.0000 - mse: 439088992.0000\n",
      "Epoch 89/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 437892044.0000 - mse: 437892032.0000\n",
      "Epoch 90/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 436626212.0000 - mse: 436626240.0000\n",
      "Epoch 91/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 435387640.0000 - mse: 435387648.0000\n",
      "Epoch 92/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 434151456.0000 - mse: 434151488.0000\n",
      "Epoch 93/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 432996812.0000 - mse: 432996800.0000\n",
      "Epoch 94/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 431713904.0000 - mse: 431713888.0000\n",
      "Epoch 95/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 430277492.0000 - mse: 430277536.0000\n",
      "Epoch 96/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 429389280.0000 - mse: 429389248.0000\n",
      "Epoch 97/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 428100496.0000 - mse: 428100512.0000\n",
      "Epoch 98/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 426865190.0000 - mse: 426865216.0000\n",
      "Epoch 99/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 425893468.0000 - mse: 425893472.0000\n",
      "Epoch 100/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 424485876.0000 - mse: 424485888.0000\n",
      "Epoch 101/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 423244616.0000 - mse: 423244640.0000\n",
      "Epoch 102/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 422183032.0000 - mse: 422183040.0000\n",
      "Epoch 103/170\n",
      "40/40 [==============================] - 0s 399us/step - loss: 420822552.0000 - mse: 420822560.0000\n",
      "Epoch 104/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 419691648.0000 - mse: 419691648.0000\n",
      "Epoch 105/170\n",
      "40/40 [==============================] - 0s 324us/step - loss: 418674664.0000 - mse: 418674656.0000\n",
      "Epoch 106/170\n",
      "40/40 [==============================] - 0s 349us/step - loss: 417428488.0000 - mse: 417428480.0000\n",
      "Epoch 107/170\n",
      "40/40 [==============================] - 0s 262us/step - loss: 416061968.0000 - mse: 416061952.0000\n",
      "Epoch 108/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 414983400.0000 - mse: 414983392.0000\n",
      "Epoch 109/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 413322128.0000 - mse: 413322144.0000\n",
      "Epoch 110/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 412231400.0000 - mse: 412231392.0000\n",
      "Epoch 111/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 411080620.0000 - mse: 411080640.0000\n",
      "Epoch 112/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 409917768.0000 - mse: 409917760.0000\n",
      "Epoch 113/170\n",
      "40/40 [==============================] - 0s 199us/step - loss: 408560608.0000 - mse: 408560576.0000\n",
      "Epoch 114/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 407522520.0000 - mse: 407522528.0000\n",
      "Epoch 115/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 406393824.0000 - mse: 406393792.0000\n",
      "Epoch 116/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 404946608.0000 - mse: 404946624.0000\n",
      "Epoch 117/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 403583128.0000 - mse: 403583136.0000\n",
      "Epoch 118/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 402640312.0000 - mse: 402640320.0000\n",
      "Epoch 119/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 401634616.0000 - mse: 401634624.0000\n",
      "Epoch 120/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 400277956.0000 - mse: 400277952.0000\n",
      "Epoch 121/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 399206384.0000 - mse: 399206400.0000\n",
      "Epoch 122/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 398191108.0000 - mse: 398191104.0000\n",
      "Epoch 123/170\n",
      "40/40 [==============================] - 0s 199us/step - loss: 396582862.0000 - mse: 396582848.0000\n",
      "Epoch 124/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 395686764.0000 - mse: 395686752.0000\n",
      "Epoch 125/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 394320220.0000 - mse: 394320224.0000\n",
      "Epoch 126/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 392797696.0000 - mse: 392797696.0000\n",
      "Epoch 127/170\n",
      "40/40 [==============================] - 0s 199us/step - loss: 391625280.0000 - mse: 391625280.0000\n",
      "Epoch 128/170\n",
      "40/40 [==============================] - 0s 175us/step - loss: 390874028.0000 - mse: 390874016.0000\n",
      "Epoch 129/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 389319296.0000 - mse: 389319296.0000\n",
      "Epoch 130/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 388026642.0000 - mse: 388026624.0000\n",
      "Epoch 131/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 387266312.0000 - mse: 387266304.0000\n",
      "Epoch 132/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 385785656.0000 - mse: 385785664.0000\n",
      "Epoch 133/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 384828720.0000 - mse: 384828736.0000\n",
      "Epoch 134/170\n",
      "40/40 [==============================] - 0s 200us/step - loss: 383435320.0000 - mse: 383435328.0000\n",
      "Epoch 135/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 382332380.0000 - mse: 382332352.0000\n",
      "Epoch 136/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 381834496.0000 - mse: 381834528.0000\n",
      "Epoch 137/170\n",
      "40/40 [==============================] - ETA: 0s - loss: 320494240.0000 - mse: 320494240.000 - 0s 199us/step - loss: 379970680.0000 - mse: 379970688.0000\n",
      "Epoch 138/170\n",
      "40/40 [==============================] - 0s 200us/step - loss: 378925720.0000 - mse: 378925728.0000\n",
      "Epoch 139/170\n",
      "40/40 [==============================] - 0s 225us/step - loss: 377796276.0000 - mse: 377796256.0000\n",
      "Epoch 140/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 376058136.0000 - mse: 376058144.0000\n",
      "Epoch 141/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 375415628.0000 - mse: 375415616.0000\n",
      "Epoch 142/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 373934160.0000 - mse: 373934176.0000\n",
      "Epoch 143/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 373536572.0000 - mse: 373536576.0000\n",
      "Epoch 144/170\n",
      "40/40 [==============================] - ETA: 0s - loss: 696151104.0000 - mse: 696151104.000 - 0s 349us/step - loss: 371866687.0000 - mse: 371866688.0000\n",
      "Epoch 145/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 370461012.0000 - mse: 370461024.0000\n",
      "Epoch 146/170\n",
      "40/40 [==============================] - 0s 524us/step - loss: 369333780.0000 - mse: 369333760.0000\n",
      "Epoch 147/170\n",
      "40/40 [==============================] - 0s 424us/step - loss: 368094514.0000 - mse: 368094528.0000\n",
      "Epoch 148/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 367063768.0000 - mse: 367063744.0000\n",
      "Epoch 149/170\n",
      "40/40 [==============================] - 0s 274us/step - loss: 366054244.0000 - mse: 366054240.0000\n",
      "Epoch 150/170\n",
      "40/40 [==============================] - 0s 299us/step - loss: 364600372.0000 - mse: 364600384.0000\n",
      "Epoch 151/170\n",
      "40/40 [==============================] - ETA: 0s - loss: 271970496.0000 - mse: 271970496.000 - 0s 224us/step - loss: 363782368.0000 - mse: 363782368.0000\n",
      "Epoch 152/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 362489168.0000 - mse: 362489152.0000\n",
      "Epoch 153/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 361478400.0000 - mse: 361478400.0000\n",
      "Epoch 154/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 360029060.0000 - mse: 360029088.0000\n",
      "Epoch 155/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 359218772.0000 - mse: 359218752.0000\n",
      "Epoch 156/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 358188634.0000 - mse: 358188608.0000\n",
      "Epoch 157/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 356761324.0000 - mse: 356761344.0000\n",
      "Epoch 158/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 355875408.0000 - mse: 355875392.0000\n",
      "Epoch 159/170\n",
      "40/40 [==============================] - 0s 275us/step - loss: 354595952.0000 - mse: 354595936.0000\n",
      "Epoch 160/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 353896824.0000 - mse: 353896832.0000\n",
      "Epoch 161/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 352265924.0000 - mse: 352265920.0000\n",
      "Epoch 162/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 351313988.0000 - mse: 351313984.0000\n",
      "Epoch 163/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 350254840.0000 - mse: 350254816.0000\n",
      "Epoch 164/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 349051876.0000 - mse: 349051840.0000\n",
      "Epoch 165/170\n",
      "40/40 [==============================] - 0s 237us/step - loss: 347753844.0000 - mse: 347753824.0000\n",
      "Epoch 166/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 346835056.0000 - mse: 346835040.0000\n",
      "Epoch 167/170\n",
      "40/40 [==============================] - 0s 199us/step - loss: 345929356.0000 - mse: 345929344.0000\n",
      "Epoch 168/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 344469052.0000 - mse: 344469056.0000\n",
      "Epoch 169/170\n",
      "40/40 [==============================] - 0s 249us/step - loss: 343594652.0000 - mse: 343594656.0000\n",
      "Epoch 170/170\n",
      "40/40 [==============================] - 0s 224us/step - loss: 342300372.0000 - mse: 342300352.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c562801b08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train,y_train , batch_size = 10,epochs = 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105355.61 ],\n",
       "       [116962.195],\n",
       "       [118719.41 ],\n",
       "       [ 72514.82 ],\n",
       "       [172073.89 ],\n",
       "       [142454.33 ],\n",
       "       [ 68776.23 ],\n",
       "       [ 87602.13 ],\n",
       "       [130292.56 ],\n",
       "       [156038.23 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103282.38],\n",
       "       [144259.4 ],\n",
       "       [146121.95],\n",
       "       [ 77798.83],\n",
       "       [191050.39],\n",
       "       [105008.31],\n",
       "       [ 81229.06],\n",
       "       [ 97483.56],\n",
       "       [110352.25],\n",
       "       [166187.94]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "accuracy = r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6837952566919291"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save('regressor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save('regressor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50580.207]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.predict(np.array([[0,1,0,50000,60000,70000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
